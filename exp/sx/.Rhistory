kKmik.mod <- kmpred %*% solve(Km, kmpred)
kKbik.mod <- kbpred %*% solve(Kb, kbpred)
kKmik.mod
kKbik.mod
pred.var.mod <- Vm*(1+eps+gb - (kKmik.mod + kKbik.mod))
pred.var.mod
(kKmik.mod + kKbik.mod)
gb
Vm
(1+eps+gb - (kKmik.mod + kKbik.mod))
sx.score <- function(Xm = NULL, yM = NULL, Xf = NULL, yF = NULL, uhat = NULL, Vm = NULL, Vb = NULL, theta_m = NULL,
theta_b = NULL, gb = NULL, Xf.test = NULL, yF.test = NULL, eps = NULL, type = NULL){
nm <- nrow(Xm)
nf <- nrow(Xf)
Xuhatf <- cbind(Xf, rep(1, times = nf) %x% t(uhat))
Xf.test.uhat <- cbind(Xf.test, rep(1, times = nrow(Xf.test)) %x% t(uhat))
Xfm <- rbind(Xuhatf, Xm)
Km.full <- cov_gen(Xfm, theta = theta_m, type = "Gaussian")
diag(Km.full) <- diag(Km.full) + eps
diag(Km.full[1:nf, 1:nf]) <- diag(Km.full[1:nf, 1:nf]) + gb
Kmb.full <- Km.full <- Km.full
KmbiY <- solve(Kmb.full, c(yF, yM))
kmbpred <- cov_gen(Xf.test.uhat, Xfm, theta = theta_m, type = "Gaussian")
Yf.hat <- kmbpred %*% KmbiY
mu.pred <- drop(Yf.hat)
### RMSE
rmse <- sqrt(mean((yF.test -mu.pred)^2))
## Score
k.pred <- cov_gen(X1 = Xfm, X2 = Xf.test.uhat, theta = theta_m, type = "Gaussian")
kKik <- crossprod(k.pred,solve(Kmb.full, k.pred))
pred.var <- Vm*(1 + eps + gb - kKik)
if(pred.var < 0){
warning("Calculated negative predictive variance for score function", immediate. = TRUE)
}
normal.kernel <- (yF.test - mu.pred)^2/pred.var
ldet.var <- -log(pred.var)
score <- ldet.var - normal.kernel
########## Modularized versions
Km <- Km.full[(nrow(Xf) + 1):nrow(Km.full),(nrow(Xf) + 1):nrow(Km.full)]
KmiyM <- solve(Km, yM)
kmpred <- kmbpred[,(nrow(Xf) + 1):nrow(Km.full)]
Kb <- Km.full[1:nrow(Xf), 1:nrow(Xf)]
kbpred <- kmbpred[,1:nrow(Xf)]
KbiyF <- solve(Kb, yF)
mu.mod <- drop(kmpred %*% KmiyM) + drop(kbpred %*% KbiyF)
kKmik.mod <- kmpred %*% solve(Km, kmpred)
kKbik.mod <- tcrossprod(kbpred,kbpred)/g#kbpred %*% solve(Kb, kbpred)
pred.var.mod <- Vm*(1+eps+gb - (kKmik.mod + kKbik.mod))
rmse.mod <- sqrt((yF.test  - mu.mod)^2)
score.mod <- -log(pred.var.mod) - (yF.test - mu.mod)^2/pred.var.mod
if(pred.var.mod < 0){
stop("Calculated negative predictive variance for modularized score function", immediate. = TRUE)
}
return(list(rmse = rmse, rmse.mod = rmse.mod, score = score, score.mod = score.mod))
}
nruns <- 13
init.mat <- matrix(NA, ncol = nruns, nrow = max.pts)
init.list <- list(score = init.mat, rmse = init.mat)
mod.metrics <- list(imspe = init.list, lhs = init.list, random = init.list)
for(s in test.types){
type.list <- performance.list[[s]]
for(j in 1:nruns){
yF <- type.list$data[[j]]$yF
Xf <- type.list$data[[j]]$Xf
Xf.test <- type.list$data[[j]]$Xf.test
yF.test <- type.list$data[[j]]$yF.test
for(i in min.pts:max.pts){
uhat <- c(type.list$uhat1[i,j], type.list$uhat2[i,j], type.list$uhat3[i,j], type.list$uhat4[i,j])
gb <- type.list$gb[i,j]
Vm <- type.list$Vm[i,j]
theta_m <- type.list$theta_m[[j]][i,]
Xm <- type.list$data[[j]]$Xm[1:i,]
yM <- type.list$data[[j]]$yM[1:i]
metrics <- sx.score(Xm = Xm, yM = yM, Xf = Xf, yF = yF, uhat = uhat, Vm = Vm, theta_m = theta_m,
gb = gb, Xf.test = Xf.test, yF.test = yF.test, eps = sqrt(.Machine$double.eps), type = "Gaussian")
mod.metrics[[s]]$score[i,j] <- metrics$score.mod
mod.metrics[[s]]$rmse[i,j] <- metrics$rmse.mod
}
}
}
sx.score <- function(Xm = NULL, yM = NULL, Xf = NULL, yF = NULL, uhat = NULL, Vm = NULL, Vb = NULL, theta_m = NULL,
theta_b = NULL, gb = NULL, Xf.test = NULL, yF.test = NULL, eps = NULL, type = NULL){
nm <- nrow(Xm)
nf <- nrow(Xf)
Xuhatf <- cbind(Xf, rep(1, times = nf) %x% t(uhat))
Xf.test.uhat <- cbind(Xf.test, rep(1, times = nrow(Xf.test)) %x% t(uhat))
Xfm <- rbind(Xuhatf, Xm)
Km.full <- cov_gen(Xfm, theta = theta_m, type = "Gaussian")
diag(Km.full) <- diag(Km.full) + eps
diag(Km.full[1:nf, 1:nf]) <- diag(Km.full[1:nf, 1:nf]) + gb
Kmb.full <- Km.full <- Km.full
KmbiY <- solve(Kmb.full, c(yF, yM))
kmbpred <- cov_gen(Xf.test.uhat, Xfm, theta = theta_m, type = "Gaussian")
Yf.hat <- kmbpred %*% KmbiY
mu.pred <- drop(Yf.hat)
### RMSE
rmse <- sqrt(mean((yF.test -mu.pred)^2))
## Score
k.pred <- cov_gen(X1 = Xfm, X2 = Xf.test.uhat, theta = theta_m, type = "Gaussian")
kKik <- crossprod(k.pred,solve(Kmb.full, k.pred))
pred.var <- Vm*(1 + eps + gb - kKik)
if(pred.var < 0){
warning("Calculated negative predictive variance for score function", immediate. = TRUE)
}
normal.kernel <- (yF.test - mu.pred)^2/pred.var
ldet.var <- -log(pred.var)
score <- ldet.var - normal.kernel
########## Modularized versions
Km <- Km.full[(nrow(Xf) + 1):nrow(Km.full),(nrow(Xf) + 1):nrow(Km.full)]
KmiyM <- solve(Km, yM)
kmpred <- kmbpred[,(nrow(Xf) + 1):nrow(Km.full)]
Kb <- Km.full[1:nrow(Xf), 1:nrow(Xf)]
kbpred <- kmbpred[,1:nrow(Xf)]
KbiyF <- solve(Kb, yF)
mu.mod <- drop(kmpred %*% KmiyM) + drop(kbpred %*% KbiyF)
kKmik.mod <- kmpred %*% solve(Km, kmpred)
kKbik.mod <- tcrossprod(kbpred,kbpred)/gb#kbpred %*% solve(Kb, kbpred)
pred.var.mod <- Vm*(1+eps+gb - (kKmik.mod + kKbik.mod))
rmse.mod <- sqrt((yF.test  - mu.mod)^2)
score.mod <- -log(pred.var.mod) - (yF.test - mu.mod)^2/pred.var.mod
if(pred.var.mod < 0){
stop("Calculated negative predictive variance for modularized score function", immediate. = TRUE)
}
return(list(rmse = rmse, rmse.mod = rmse.mod, score = score, score.mod = score.mod))
}
nruns <- 13
init.mat <- matrix(NA, ncol = nruns, nrow = max.pts)
init.list <- list(score = init.mat, rmse = init.mat)
mod.metrics <- list(imspe = init.list, lhs = init.list, random = init.list)
for(s in test.types){
type.list <- performance.list[[s]]
for(j in 1:nruns){
yF <- type.list$data[[j]]$yF
Xf <- type.list$data[[j]]$Xf
Xf.test <- type.list$data[[j]]$Xf.test
yF.test <- type.list$data[[j]]$yF.test
for(i in min.pts:max.pts){
uhat <- c(type.list$uhat1[i,j], type.list$uhat2[i,j], type.list$uhat3[i,j], type.list$uhat4[i,j])
gb <- type.list$gb[i,j]
Vm <- type.list$Vm[i,j]
theta_m <- type.list$theta_m[[j]][i,]
Xm <- type.list$data[[j]]$Xm[1:i,]
yM <- type.list$data[[j]]$yM[1:i]
metrics <- sx.score(Xm = Xm, yM = yM, Xf = Xf, yF = yF, uhat = uhat, Vm = Vm, theta_m = theta_m,
gb = gb, Xf.test = Xf.test, yF.test = yF.test, eps = sqrt(.Machine$double.eps), type = "Gaussian")
mod.metrics[[s]]$score[i,j] <- metrics$score.mod
mod.metrics[[s]]$rmse[i,j] <- metrics$rmse.mod
}
}
}
nm <- nrow(Xm)
nf <- nrow(Xf)
Xuhatf <- cbind(Xf, rep(1, times = nf) %x% t(uhat))
Xf.test.uhat <- cbind(Xf.test, rep(1, times = nrow(Xf.test)) %x% t(uhat))
Xfm <- rbind(Xuhatf, Xm)
Km.full <- cov_gen(Xfm, theta = theta_m, type = "Gaussian")
diag(Km.full) <- diag(Km.full) + eps
diag(Km.full[1:nf, 1:nf]) <- diag(Km.full[1:nf, 1:nf]) + gb
Kmb.full <- Km.full <- Km.full
KmbiY <- solve(Kmb.full, c(yF, yM))
kmbpred <- cov_gen(Xf.test.uhat, Xfm, theta = theta_m, type = "Gaussian")
Yf.hat <- kmbpred %*% KmbiY
mu.pred <- drop(Yf.hat)
### RMSE
rmse <- sqrt(mean((yF.test -mu.pred)^2))
## Score
k.pred <- cov_gen(X1 = Xfm, X2 = Xf.test.uhat, theta = theta_m, type = "Gaussian")
kKik <- crossprod(k.pred,solve(Kmb.full, k.pred))
pred.var <- Vm*(1 + eps + gb - kKik)
if(pred.var < 0){
warning("Calculated negative predictive variance for score function", immediate. = TRUE)
}
normal.kernel <- (yF.test - mu.pred)^2/pred.var
ldet.var <- -log(pred.var)
score <- ldet.var - normal.kernel
########## Modularized versions
Km <- Km.full[(nrow(Xf) + 1):nrow(Km.full),(nrow(Xf) + 1):nrow(Km.full)]
KmiyM <- solve(Km, yM)
kmpred <- kmbpred[,(nrow(Xf) + 1):nrow(Km.full)]
Kb <- Km.full[1:nrow(Xf), 1:nrow(Xf)]
kbpred <- kmbpred[,1:nrow(Xf)]
KbiyF <- solve(Kb, yF)
mu.mod <- drop(kmpred %*% KmiyM) + drop(kbpred %*% KbiyF)
kKmik.mod <- kmpred %*% solve(Km, kmpred)
kKbik.mod <- tcrossprod(kbpred,kbpred)/gb#kbpred %*% solve(Kb,
kBik.mod
kKbik.mod
sx.score <- function(Xm = NULL, yM = NULL, Xf = NULL, yF = NULL, uhat = NULL, Vm = NULL, Vb = NULL, theta_m = NULL,
theta_b = NULL, gb = NULL, Xf.test = NULL, yF.test = NULL, eps = NULL, type = NULL){
nm <- nrow(Xm)
nf <- nrow(Xf)
Xuhatf <- cbind(Xf, rep(1, times = nf) %x% t(uhat))
Xf.test.uhat <- cbind(Xf.test, rep(1, times = nrow(Xf.test)) %x% t(uhat))
Xfm <- rbind(Xuhatf, Xm)
Km.full <- cov_gen(Xfm, theta = theta_m, type = "Gaussian")
diag(Km.full) <- diag(Km.full) + eps
diag(Km.full[1:nf, 1:nf]) <- diag(Km.full[1:nf, 1:nf]) + gb
Kmb.full <- Km.full <- Km.full
KmbiY <- solve(Kmb.full, c(yF, yM))
kmbpred <- cov_gen(Xf.test.uhat, Xfm, theta = theta_m, type = "Gaussian")
Yf.hat <- kmbpred %*% KmbiY
mu.pred <- drop(Yf.hat)
### RMSE
rmse <- sqrt(mean((yF.test -mu.pred)^2))
## Score
k.pred <- cov_gen(X1 = Xfm, X2 = Xf.test.uhat, theta = theta_m, type = "Gaussian")
kKik <- crossprod(k.pred,solve(Kmb.full, k.pred))
pred.var <- Vm*(1 + eps + gb - kKik)
if(pred.var < 0){
warning("Calculated negative predictive variance for score function", immediate. = TRUE)
}
normal.kernel <- (yF.test - mu.pred)^2/pred.var
ldet.var <- -log(pred.var)
score <- ldet.var - normal.kernel
########## Modularized versions
Km <- Km.full[(nrow(Xf) + 1):nrow(Km.full),(nrow(Xf) + 1):nrow(Km.full)]
KmiyM <- solve(Km, yM)
kmpred <- kmbpred[,(nrow(Xf) + 1):nrow(Km.full)]
Kb <- Km.full[1:nrow(Xf), 1:nrow(Xf)]
kbpred <- kmbpred[,1:nrow(Xf)]
KbiyF <- solve(Kb, yF)
mu.mod <- drop(kmpred %*% KmiyM) + drop(kbpred %*% KbiyF)
kKmik.mod <- kmpred %*% solve(Km, kmpred)
kKbik.mod <- crossprod(kbpred,kbpred)/gb#kbpred %*% solve(Kb, kbpred)
pred.var.mod <- Vm*(1+eps+gb - (kKmik.mod + kKbik.mod))
rmse.mod <- sqrt((yF.test  - mu.mod)^2)
score.mod <- -log(pred.var.mod) - (yF.test - mu.mod)^2/pred.var.mod
if(pred.var.mod < 0){
stop("Calculated negative predictive variance for modularized score function", immediate. = TRUE)
}
return(list(rmse = rmse, rmse.mod = rmse.mod, score = score, score.mod = score.mod))
}
nruns <- 13
init.mat <- matrix(NA, ncol = nruns, nrow = max.pts)
init.list <- list(score = init.mat, rmse = init.mat)
mod.metrics <- list(imspe = init.list, lhs = init.list, random = init.list)
for(s in test.types){
type.list <- performance.list[[s]]
for(j in 1:nruns){
yF <- type.list$data[[j]]$yF
Xf <- type.list$data[[j]]$Xf
Xf.test <- type.list$data[[j]]$Xf.test
yF.test <- type.list$data[[j]]$yF.test
for(i in min.pts:max.pts){
uhat <- c(type.list$uhat1[i,j], type.list$uhat2[i,j], type.list$uhat3[i,j], type.list$uhat4[i,j])
gb <- type.list$gb[i,j]
Vm <- type.list$Vm[i,j]
theta_m <- type.list$theta_m[[j]][i,]
Xm <- type.list$data[[j]]$Xm[1:i,]
yM <- type.list$data[[j]]$yM[1:i]
metrics <- sx.score(Xm = Xm, yM = yM, Xf = Xf, yF = yF, uhat = uhat, Vm = Vm, theta_m = theta_m,
gb = gb, Xf.test = Xf.test, yF.test = yF.test, eps = sqrt(.Machine$double.eps), type = "Gaussian")
mod.metrics[[s]]$score[i,j] <- metrics$score.mod
mod.metrics[[s]]$rmse[i,j] <- metrics$rmse.mod
}
}
}
mu.mod
yF.test
Vb*gb
Vm*gb
test.mat <- matrix(0, ncol = nm + nf + 1, nrow = nm + nf + 1)
test.mat
test.mat[1,1] <- 1 + eps + gb
kmpred
str(kmpred)
test.mat[2:(nf + nm + 1), ] <- c(kbpred, kmpred)
test.mat[,2:(nf + nm + 1)] <- c(kbpred, kmpred)
test.mat[2:(nf + 1), 2:(nf + 1)] <- Kb
test.mat[(nf + 2):(nf + nm + 1), (nf + 2):(nf + nm + 1)] <- Km
test.mat
test.mat[(nf + 2):nrow(test.mat), (nf+2):nrow(test.mat)]
test.mat[(nf + 20):nrow(test.mat), (nf+20):nrow(test.mat)]
test.mat[(nf + 40):nrow(test.mat), (nf+40):nrow(test.mat)]
test.mat[2:nf, 2:nf]
gb
matrixcalc::is.positive.definite(test.mat)
isSymmetric(test.mat)
isSymmetric(test.mat[2:(nf + nm +1), 2:(nf + nm + 1)])
matrixcalc::is.positive.definite(test.mat[2:(nf + nm +1), 2:(nf + nm + 1)])
matrixcalc::is.positive.definite(test.mat[2:(nf + 1), 2:(nf + 1)])
matrixcalc::is.positive.definite(test.mat[(nf + 2):nrow(test.mat), (nf + 2):nrow(test.mat)])
matrixcalc::is.positive.definite(diag(10))
diag(test.mat)
diag(test.mat) > 0
any(!(diag(test.mat) > 0))
chol(test.mat)
determinant(test.mat)
?determinant
determinant(test.mat, logarithm = FALSE)
(kKmik.mod + kKbik.mod)
nm <- nrow(Xm)
nf <- nrow(Xf)
Xuhatf <- cbind(Xf, rep(1, times = nf) %x% t(uhat))
Xf.test.uhat <- cbind(Xf.test, rep(1, times = nrow(Xf.test)) %x% t(uhat))
Xfm <- rbind(Xuhatf, Xm)
Km.full <- cov_gen(Xfm, theta = theta_m, type = "Gaussian")
diag(Km.full) <- diag(Km.full) + eps
diag(Km.full[1:nf, 1:nf]) <- diag(Km.full[1:nf, 1:nf]) + gb
Kmb.full <- Km.full <- Km.full
KmbiY <- solve(Kmb.full, c(yF, yM))
kmbpred <- cov_gen(Xf.test.uhat, Xfm, theta = theta_m, type = "Gaussian")
Yf.hat <- kmbpred %*% KmbiY
mu.pred <- drop(Yf.hat)
### RMSE
rmse <- sqrt(mean((yF.test -mu.pred)^2))
## Score
k.pred <- cov_gen(X1 = Xfm, X2 = Xf.test.uhat, theta = theta_m, type = "Gaussian")
kKik <- crossprod(k.pred,solve(Kmb.full, k.pred))
pred.var <- Vm*(1 + eps + gb - kKik)
if(pred.var < 0){
warning("Calculated negative predictive variance for score function", immediate. = TRUE)
}
normal.kernel <- (yF.test - mu.pred)^2/pred.var
ldet.var <- -log(pred.var)
score <- ldet.var - normal.kernel
########## Modularized versions
Km <- Km.full[(nrow(Xf) + 1):nrow(Km.full),(nrow(Xf) + 1):nrow(Km.full)]
KmiyM <- solve(Km, yM)
kmpred <- kmbpred[,(nrow(Xf) + 1):nrow(Km.full)]
Kb <- Km.full[1:nrow(Xf), 1:nrow(Xf)]
kbpred <- kmbpred[,1:nrow(Xf)]
KbiyF <- solve(Kb, yF)
mu.mod <- drop(kmpred %*% KmiyM) + drop(kbpred %*% KbiyF)
kKmik.mod <- kmpred %*% solve(Km, kmpred)
kKbik.mod <- kbpred %*% solve(Kb, kbpred)
kKmik.mod + kKbik.mod
solve(Kb, kbpred)
eigen(test.mat[2:nrow(test.mat), 2:nrow(test.mat)])
matrixcalc::is.positive.definite(diag(2) %x% Kb)
matrixcalc::is.positive.definite(diag(2) %x% Km)
test.mat[,2]
test.mat[,1]
str(test.mat)
test.mat[,3]
test.mat <- matrix(0, ncol = nm + nf + 1, nrow = nm + nf + 1)
test.mat[1,1] <- 1 + eps + gb
test.mat[2:(nf + nm + 1), 1] <- c(kbpred, kmpred)
test.mat[1,2:(nf + nm + 1)] <- c(kbpred, kmpred)
test.mat[2:(nf + 1), 2:(nf + 1)] <- Kb
test.mat[(nf + 2):(nf + nm + 1), (nf + 2):(nf + nm + 1)] <- Km
test.mat
matrixcalc::is.positive.definite(test.mat)
matrixcalc::is.positive.definite(test.mat[2:nrow(test.mat), 2:nrow(test.mat)])
determinant(test.mat, logarithm = FALSE)
test.mat.2 <- test.mat[1:(nf + 2), 1:(nf + 2)]
test.mat.2
matrixcalc::is.positive.definite(test.mat.2)
test.mat.2 <- test.mat[1:(nf + 3), 1:(nf + 3)]
matrixcalc::is.positive.definite(test.mat.2)
test.mat.2 <- test.mat[1:(nf + 4), 1:(nf + 4)]
matrixcalc::is.positive.definite(test.mat.2)
test.mat.2 <- test.mat[1:(nf + 5), 1:(nf + 5)]
matrixcalc::is.positive.definite(test.mat.2)
test.mat.2 <- test.mat[1:(nf + 10), 1:(nf + 10)]
matrixcalc::is.positive.definite(test.mat.2)
test.mat.2 <- test.mat[1:(nf + 7), 1:(nf + 7)]
matrixcalc::is.positive.definite(test.mat.2)
test.mat.2 <- test.mat[1:(nf + 8), 1:(nf + 8)]
matrixcalc::is.positive.definite(test.mat.2)
test.mat.2
isSymmetric(test.mat.2)
determinant(test.mat.2, logarithm = FALSE)
sx.score <- function(Xm = NULL, yM = NULL, Xf = NULL, yF = NULL, uhat = NULL, Vm = NULL, Vb = NULL, theta_m = NULL,
theta_b = NULL, gb = NULL, Xf.test = NULL, yF.test = NULL, eps = NULL, type = NULL){
nm <- nrow(Xm)
nf <- nrow(Xf)
Xuhatf <- cbind(Xf, rep(1, times = nf) %x% t(uhat))
Xf.test.uhat <- cbind(Xf.test, rep(1, times = nrow(Xf.test)) %x% t(uhat))
Xfm <- rbind(Xuhatf, Xm)
Km.full <- cov_gen(Xfm, theta = theta_m, type = "Gaussian")
diag(Km.full) <- diag(Km.full) + eps
diag(Km.full[1:nf, 1:nf]) <- diag(Km.full[1:nf, 1:nf]) + gb
Kmb.full <- Km.full <- Km.full
KmbiY <- solve(Kmb.full, c(yF, yM))
kmbpred <- cov_gen(Xf.test.uhat, Xfm, theta = theta_m, type = "Gaussian")
Yf.hat <- kmbpred %*% KmbiY
mu.pred <- drop(Yf.hat)
### RMSE
rmse <- sqrt(mean((yF.test -mu.pred)^2))
## Score
k.pred <- cov_gen(X1 = Xfm, X2 = Xf.test.uhat, theta = theta_m, type = "Gaussian")
kKik <- crossprod(k.pred,solve(Kmb.full, k.pred))
pred.var <- Vm*(1 + eps + gb - kKik)
if(pred.var < 0){
warning("Calculated negative predictive variance for score function", immediate. = TRUE)
}
normal.kernel <- (yF.test - mu.pred)^2/pred.var
ldet.var <- -log(pred.var)
score <- ldet.var - normal.kernel
########## Modularized versions
Km <- Km.full[(nrow(Xf) + 1):nrow(Km.full),(nrow(Xf) + 1):nrow(Km.full)]
KmiyM <- solve(Km, yM)
kmpred <- kmbpred[,(nrow(Xf) + 1):nrow(Km.full)]
Kb <- Km.full[1:nrow(Xf), 1:nrow(Xf)]
kbpred <- kmbpred[,1:nrow(Xf)]
KbiyF <- solve(Kb, yF)
mu.mod <- drop(kmpred %*% KmiyM)# + drop(kbpred %*% KbiyF)
kKmik.mod <- kmpred %*% solve(Km, kmpred)
kKbik.mod <- kbpred %*% solve(Kb, kbpred)
pred.var.mod <- Vm*(1+eps + g - (kKmik.mod))
rmse.mod <- sqrt((yF.test  - mu.mod)^2)
score.mod <- -log(pred.var.mod) - (yF.test - mu.mod)^2/pred.var.mod
if(pred.var.mod < 0){
stop("Calculated negative predictive variance for modularized score function", immediate. = TRUE)
}
return(list(rmse = rmse, rmse.mod = rmse.mod, score = score, score.mod = score.mod))
}
nruns <- 13
init.mat <- matrix(NA, ncol = nruns, nrow = max.pts)
init.list <- list(score = init.mat, rmse = init.mat)
mod.metrics <- list(imspe = init.list, lhs = init.list, random = init.list)
for(s in test.types){
type.list <- performance.list[[s]]
for(j in 1:nruns){
yF <- type.list$data[[j]]$yF
Xf <- type.list$data[[j]]$Xf
Xf.test <- type.list$data[[j]]$Xf.test
yF.test <- type.list$data[[j]]$yF.test
for(i in min.pts:max.pts){
uhat <- c(type.list$uhat1[i,j], type.list$uhat2[i,j], type.list$uhat3[i,j], type.list$uhat4[i,j])
gb <- type.list$gb[i,j]
Vm <- type.list$Vm[i,j]
theta_m <- type.list$theta_m[[j]][i,]
Xm <- type.list$data[[j]]$Xm[1:i,]
yM <- type.list$data[[j]]$yM[1:i]
metrics <- sx.score(Xm = Xm, yM = yM, Xf = Xf, yF = yF, uhat = uhat, Vm = Vm, theta_m = theta_m,
gb = gb, Xf.test = Xf.test, yF.test = yF.test, eps = sqrt(.Machine$double.eps), type = "Gaussian")
mod.metrics[[s]]$score[i,j] <- metrics$score.mod
mod.metrics[[s]]$rmse[i,j] <- metrics$rmse.mod
}
}
}
sx.score <- function(Xm = NULL, yM = NULL, Xf = NULL, yF = NULL, uhat = NULL, Vm = NULL, Vb = NULL, theta_m = NULL,
theta_b = NULL, gb = NULL, Xf.test = NULL, yF.test = NULL, eps = NULL, type = NULL){
nm <- nrow(Xm)
nf <- nrow(Xf)
Xuhatf <- cbind(Xf, rep(1, times = nf) %x% t(uhat))
Xf.test.uhat <- cbind(Xf.test, rep(1, times = nrow(Xf.test)) %x% t(uhat))
Xfm <- rbind(Xuhatf, Xm)
Km.full <- cov_gen(Xfm, theta = theta_m, type = "Gaussian")
diag(Km.full) <- diag(Km.full) + eps
diag(Km.full[1:nf, 1:nf]) <- diag(Km.full[1:nf, 1:nf]) + gb
Kmb.full <- Km.full <- Km.full
KmbiY <- solve(Kmb.full, c(yF, yM))
kmbpred <- cov_gen(Xf.test.uhat, Xfm, theta = theta_m, type = "Gaussian")
Yf.hat <- kmbpred %*% KmbiY
mu.pred <- drop(Yf.hat)
### RMSE
rmse <- sqrt(mean((yF.test -mu.pred)^2))
## Score
k.pred <- cov_gen(X1 = Xfm, X2 = Xf.test.uhat, theta = theta_m, type = "Gaussian")
kKik <- crossprod(k.pred,solve(Kmb.full, k.pred))
pred.var <- Vm*(1 + eps + gb - kKik)
if(pred.var < 0){
warning("Calculated negative predictive variance for score function", immediate. = TRUE)
}
normal.kernel <- (yF.test - mu.pred)^2/pred.var
ldet.var <- -log(pred.var)
score <- ldet.var - normal.kernel
########## Modularized versions
Km <- Km.full[(nrow(Xf) + 1):nrow(Km.full),(nrow(Xf) + 1):nrow(Km.full)]
KmiyM <- solve(Km, yM)
kmpred <- kmbpred[,(nrow(Xf) + 1):nrow(Km.full)]
Kb <- Km.full[1:nrow(Xf), 1:nrow(Xf)]
kbpred <- kmbpred[,1:nrow(Xf)]
KbiyF <- solve(Kb, yF)
mu.mod <- drop(kmpred %*% KmiyM)# + drop(kbpred %*% KbiyF)
kKmik.mod <- kmpred %*% solve(Km, kmpred)
kKbik.mod <- kbpred %*% solve(Kb, kbpred)
pred.var.mod <- Vm*(1+eps + gb - (kKmik.mod))
rmse.mod <- sqrt((yF.test  - mu.mod)^2)
score.mod <- -log(pred.var.mod) - (yF.test - mu.mod)^2/pred.var.mod
if(pred.var.mod < 0){
stop("Calculated negative predictive variance for modularized score function", immediate. = TRUE)
}
return(list(rmse = rmse, rmse.mod = rmse.mod, score = score, score.mod = score.mod))
}
nruns <- 13
init.mat <- matrix(NA, ncol = nruns, nrow = max.pts)
init.list <- list(score = init.mat, rmse = init.mat)
mod.metrics <- list(imspe = init.list, lhs = init.list, random = init.list)
for(s in test.types){
type.list <- performance.list[[s]]
for(j in 1:nruns){
yF <- type.list$data[[j]]$yF
Xf <- type.list$data[[j]]$Xf
Xf.test <- type.list$data[[j]]$Xf.test
yF.test <- type.list$data[[j]]$yF.test
for(i in min.pts:max.pts){
uhat <- c(type.list$uhat1[i,j], type.list$uhat2[i,j], type.list$uhat3[i,j], type.list$uhat4[i,j])
gb <- type.list$gb[i,j]
Vm <- type.list$Vm[i,j]
theta_m <- type.list$theta_m[[j]][i,]
Xm <- type.list$data[[j]]$Xm[1:i,]
yM <- type.list$data[[j]]$yM[1:i]
metrics <- sx.score(Xm = Xm, yM = yM, Xf = Xf, yF = yF, uhat = uhat, Vm = Vm, theta_m = theta_m,
gb = gb, Xf.test = Xf.test, yF.test = yF.test, eps = sqrt(.Machine$double.eps), type = "Gaussian")
mod.metrics[[s]]$score[i,j] <- metrics$score.mod
mod.metrics[[s]]$rmse[i,j] <- metrics$rmse.mod
}
}
}
plot(apply(mod.metrics$imspe$rmse,1,mean, na.rm = TRUE), type ="l")
plot(apply(mod.metrics$imspe$score,1,mean, na.rm = TRUE), type ="l")
pts.important <- min.pts:max.pts
run.vec <- 1:13
plot(apply(performance.list$imspe$rmse[pts.important,run.vec, drop = FALSE],1,mean), type = "l", col = "blue")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
file.path <- "~/Documents/gramacy-lab/kohdesign/exp/sx/"
deleteGPseps()
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
